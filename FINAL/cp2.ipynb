{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dedcc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:04:07.974696: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import glob as gb\n",
    "import seaborn as sns\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6169522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "SEED = 1000\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "TRAIN_DIR = '/Users/paris/Desktop/os/train'\n",
    "TEST_DIR = '/Users/paris/Desktop/os/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdcc661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5778\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "class_count = []\n",
    "train_exm = 0\n",
    "for f in os.listdir(TRAIN_DIR):\n",
    "    files = gb.glob(pathname=str(TRAIN_DIR  + '//' + f + '/*.png'))\n",
    "    categories.append(f)\n",
    "    class_count.append(len(files))\n",
    "    train_exm += len(files)\n",
    "\n",
    "sns.barplot(x=categories, y=class_count).set_title(\"distribution of train data\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(train_exm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533f8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    validation_split = 0.2,\n",
    "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "    # dtype = tf.float32\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "    # dtype = tf.float32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43d5e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4624 images belonging to 5 classes.\n",
      "Found 1154 images belonging to 5 classes.\n",
      "Found 1656 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch = train_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    "    subset = 'training',\n",
    "    seed = SEED\n",
    ")\n",
    "valid_batch = train_gen.flow_from_directory(\n",
    "    directory=TRAIN_DIR,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    "    subset = 'validation',\n",
    "    seed = SEED\n",
    ")\n",
    "test_batch = test_gen.flow_from_directory(\n",
    "    directory=TEST_DIR,\n",
    "    target_size = (IMG_SIZE, IMG_SIZE),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'sparse',\n",
    "    seed = SEED\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c207c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-17 13:04:17.611263: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape = (IMG_SIZE, IMG_SIZE) + (3,)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False,  weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2c9be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,142,213\n",
      "Trainable params: 15,142,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_SIZE,IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98c4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821233c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 178s 9s/step - loss: 3.4155 - accuracy: 0.2734 - val_loss: 1.4244 - val_accuracy: 0.4141\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    train_batch,\n",
    "    steps_per_epoch = 642 // BATCH_SIZE,\n",
    "    validation_data=valid_batch,\n",
    "    validation_steps=158 // BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf86de58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape = (IMG_SIZE, IMG_SIZE) + (3,)\n",
    "base_model = tf.keras.applications.VGG16(input_shape=img_shape, include_top=False, weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True  \n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29941844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,142,213\n",
      "Trainable params: 15,142,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5088a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss= tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "602e7489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 194s 10s/step - loss: 1.4974 - accuracy: 0.3391 - val_loss: 1.4663 - val_accuracy: 0.3828\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    train_batch,\n",
    "    steps_per_epoch = 642 // BATCH_SIZE,\n",
    "    validation_data=valid_batch,\n",
    "    validation_steps=158 // BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6712d8",
   "metadata": {},
   "source": [
    "Here, by freezing layer the accuracy was 0.2734 and without freezing layers the accuracy is 0.3391 ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
